spiral_dynamics.py:


import os
import json
from openai import OpenAI

# Constants and config
STAGES = ["Beige", "Purple", "Red", "Blue", "Orange", "Green", "Yellow", "Turquoise"]

STAGE_GAMIFIED_META = {
    "Beige": {"emoji": "ðŸŸ¤", "name": "Beige", "reward": "Basic awareness"},
    "Purple": {"emoji": "ðŸŸ£", "name": "Purple", "reward": "Group belonging"},
    "Red": {"emoji": "ðŸ”´", "name": "Red", "reward": "Power attainment"},
    "Blue": {"emoji": "ðŸ”µ", "name": "Blue", "reward": "Order and stability"},
    "Orange": {"emoji": "ðŸŸ ", "name": "Orange", "reward": "Achievement"},
    "Green": {"emoji": "ðŸŸ¢", "name": "Green", "reward": "Community and connection"},
    "Yellow": {"emoji": "ðŸŸ¡", "name": "Yellow", "reward": "Integration"},
    "Turquoise": {"emoji": "ðŸ”·", "name": "Turquoise", "reward": "Global consciousness"},
}

# Read OpenAI key from environment
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("âŒ Missing OPENAI_API_KEY environment variable")

client = OpenAI(api_key=OPENAI_API_KEY)

def detect_intent(entry: str) -> str:
    prompt = (
        "You are a Spiral Dynamics gatekeeper.\n"
        "Determine if this journal entry reflects emotional expression, life struggle, desire for change, personal values, reflection, or self-awareness.\n"
        "If yes, return 'spiral'. If it's only surface-level chat, jokes, or small talk, return 'chat'.\n"
        f"Entry: \"{entry}\""
    )
    response = client.chat.completions.create(
        model="gpt-4.1",
        messages=[{"role": "user", "content": prompt}],
        temperature=0,
    )
    content = response.choices[0].message.content.lower()
    return "spiral" if "spiral" in content else "chat"


def classify_stage(entry: str, context: str = None) -> dict:
    """
    Classify the entry into a Spiral Dynamics stage.
    Optional 'context' can be provided (short conversation history) to improve classification.
    Returns dict with keys: stage, secondary, confidence, reason
    """
    ctx_part = f"\nContext:\n{context}\n" if context else ""
    prompt = (
        f"Analyze this user input and classify its dominant Spiral Dynamics stage from: {', '.join(STAGES)}.\n"
        "Respond with JSON containing:\n"
        "- 'primary_stage': The most dominant stage\n"
        "- 'secondary_stage': Second most present stage (if any)\n"
        "- 'confidence': Your confidence in primary stage (0-1)\n"
        "- 'reason': Brief explanation of your choice\n\n"
        f"{ctx_part}\nInput: \"{entry}\""
    )
    response = client.chat.completions.create(
        model="gpt-4.1",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
        response_format={"type": "json_object"}
    )
    try:
        result = json.loads(response.choices[0].message.content)
        return {
            "stage": result.get("primary_stage", "Unknown"),
            "secondary": result.get("secondary_stage"),
            "confidence": float(result.get("confidence", 0)),
            "reason": result.get("reason", "")
        }
    except Exception:
        # fallback: simple classification without structured JSON
        fallback = client.chat.completions.create(
            model="gpt-4.1",
            messages=[{"role": "user", "content": f"Classify this into one stage from {', '.join(STAGES)}: {entry}"}],
            temperature=0
        )
        return {
            "stage": fallback.choices[0].message.content.strip(),
            "secondary": None,
            "confidence": 1.0,
            "reason": ""
        }


def check_evolution(last_stage: str, current_result: dict) -> str:
    if not last_stage:
        return None
    current_stage = current_result.get("stage", "Unknown")
    try:
        last_idx = STAGES.index(last_stage)
        current_idx = STAGES.index(current_stage)
        confidence = current_result.get("confidence", 0)
        if current_idx > last_idx and confidence >= 0.6:
            return f"ðŸŒ± Level Up! You're showing strong {current_stage} tendencies!"
        elif current_idx > last_idx:
            return f"ðŸŒ€ Exploring {current_stage}, with elements of {last_stage}."
    except ValueError:
        pass
    return None


def generate_reflective_question(entry: str, reply_to: str = None, context: str = None) -> str:
    """
    Generate a short reflective question based on the user's entry.
    Accepts optional reply_to and a short context (conversation history) to make questions more targeted.
    """
    ctx = ""
    if reply_to:
        ctx += f"\nReplying to: \"{reply_to}\""
    if context:
        ctx += f"\nContext: {context}"
    prompt = (
        f"You are a Spiral Dynamics mentor. Based on the user's thoughts{ctx}, "
        "ask one deep, emotionally resonant question (max 15 words). Just ask the question.\n\n"
        f"User message: \"{entry}\""
    )
    response = client.chat.completions.create(
        model="gpt-4.1",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.85
    )
    return response.choices[0].message.content.strip()


def generate_gamified_prompt(stage: str, entry: str, evolution: bool = False) -> dict:
    stage_meta = STAGE_GAMIFIED_META.get(stage, STAGE_GAMIFIED_META["Green"])
    prompt_template = (
        f"Create a gamified interaction for a user at the {stage} stage of Spiral Dynamics. "
        f"The user just shared: '{entry}'\n\n"
        "Provide:\n"
        "1. A VERY short reflective question (5-10 words) to deepen their awareness\n"
        "2. A concrete action prompt (max 15 words) aligned with their stage\n"
        "3. A stage-appropriate reward description\n"
        "Format as JSON with keys: question, prompt, reward"
    )
    response = client.chat.completions.create(
        model="gpt-4.1",
        messages=[{"role": "user", "content": prompt_template}],
        temperature=0.7,
        response_format={"type": "json_object"}
    )
    try:
        content = json.loads(response.choices[0].message.content)
        return {
            "gamified_question": f"{stage_meta['emoji']} {stage_meta['name']}\nðŸŽ¯ {content.get('question','')}",
            "gamified_prompt": f"ðŸ’¡ {content.get('prompt','')}",
            "reward": content.get('reward') if evolution else stage_meta["reward"]
        }
    except Exception:
        return {
            "gamified_question": f"{stage_meta['emoji']} {stage_meta['name']}\nðŸŽ¯ What about this resonates most with you?",
            "gamified_prompt": "ðŸ’¡ Reflect on how this shows up in your daily life",
            "reward": stage_meta["reward"]
        }

routes.py:
from flask import Blueprint, request, jsonify
import json
import os
import traceback
from datetime import datetime
from collections import defaultdict
import requests

# Import your project modules - adjust import paths as necessary
from tasks import generate_daily_task, save_completed_task, get_user_tasks
from rewards import get_user_progress, save_user_progress, update_streak, check_streak_rewards, check_message_rewards
from spiral_dynamics import detect_intent, classify_stage, check_evolution, generate_reflective_question, generate_gamified_prompt
from firebase_utils import db, save_conversation_message, get_recent_conversation
from notifications import send_welcome_notification
# from openai import OpenAI  # Your AI client instance configured elsewhere
from spiral_dynamics import client  # Your OpenAI client instance

bp = Blueprint('main', __name__)

AUDIO_FOLDER = "audios"
os.makedirs(AUDIO_FOLDER, exist_ok=True)

# How many last messages to include as context (adjust as needed)
HISTORY_LIMIT = 6

XP_REWARDS = {
    "level_up": 10,
    "daily_streak_3": 15,
    "daily_streak_7": 30,
    "daily_streak_14": 50,
    "daily_streak_30": 100,
    "message_streak": 20,
}

BADGES = {
    "level_up": "ðŸŒ± Level Up",
    "daily_streak_3": "ðŸ”¥ 3-Day Streak",
    "daily_streak_7": "ðŸŒŸ Weekly Explorer",
    "daily_streak_14": "ðŸŒ™ Fortnight Champion",
    "daily_streak_30": "ðŸŒ• Monthly Master",
    "message_streak": "ðŸ’¬ Chatterbox",
}

# âœ… New mission milestone rewards
MISSION_REWARDS = {
    1: {"xp": 20, "badge": "ðŸŽ¯ First Mission"},
    5: {"xp": 50, "badge": "ðŸ… Mission Explorer"},
    10: {"xp": 100, "badge": "ðŸš€ Mission Master"},
}


@bp.route('/')
def home():
    return "Backend is running"


@bp.route('/daily_task', methods=['GET'])
def daily_task():
    user_id = request.args.get("user_id")
    if not user_id:
        return jsonify({"error": "Missing user_id"}), 400
    try:
        task = generate_daily_task()
        with open("completed_tasks.json") as f:
            completed = json.load(f)
        user_done = any(
            t for t in completed if t.get("user_id") == user_id and t.get("date") == task.get("date") and t.get("completed")
        )
        task["user_done"] = user_done
        return jsonify(task)
    except Exception:
        traceback.print_exc()
        return jsonify({"error": "Failed to fetch daily task"}), 500


@bp.route('/complete_task', methods=['POST'])
def complete_task():
    data = request.json
    user_id = data.get("user_id")
    task_id = data.get("task_id")
    if not user_id or not task_id:
        return jsonify({"error": "Missing user_id or task_id"}), 400
    try:
        with open("daily_tasks.json") as f:
            tasks = json.load(f)
        task_to_complete = next((t for t in tasks if str(t.get("timestamp")) == task_id and t.get("user_id") == user_id), None)
        if not task_to_complete:
            return jsonify({"error": "Task not found"}), 404
        task_to_complete["completed"] = True
        task_to_complete["completion_timestamp"] = datetime.utcnow().isoformat()
        with open("daily_tasks.json", "w") as f:
            json.dump(tasks, f, indent=2)
        save_completed_task(user_id, task_to_complete)
        return jsonify({"message": "Task marked completed"})
    except Exception:
        traceback.print_exc()
        return jsonify({"error": "Failed to complete task"}), 500


@bp.route('/task_history', methods=['GET'])
def task_history():
    user_id = request.args.get("user_id")
    if not user_id:
        return jsonify({"error": "Missing user_id"}), 400
    try:
        tasks = get_user_tasks(user_id, "completed_tasks.json")
        return jsonify(tasks)
    except Exception:
        traceback.print_exc()
        return jsonify({"error": "Failed to fetch task history"}), 500


@bp.route('/user_progress', methods=['GET'])
def user_progress():
    user_id = request.args.get("user_id")
    if not user_id:
        return jsonify({"error": "Missing user_id"}), 400
    try:
        progress = get_user_progress(user_id)
        return jsonify(progress)
    except Exception:
        traceback.print_exc()
        return jsonify({"error": "Failed to fetch user progress"}), 500


@bp.route('/merged', methods=['POST'])
def merged():
    """
    Main endpoint for both chat (casual) and spiral (reflection) processing.
    This endpoint now:
    - saves incoming user messages to Firestore (if user_id provided)
    - fetches recent conversation history and includes it in the OpenAI chat call
    - saves the assistant's reply back to Firestore
    All existing gamification, streak and mission logic is preserved.
    """
    try:
        data = request.json
        entry = data.get("text", "").strip()
        last_stage = data.get("last_stage", "").strip()
        reply_to = data.get("reply_to", "").strip()
        user_id = data.get("user_id")
        if not entry:
            return jsonify({"error": "Missing entry"}), 400

        streak = 0
        rewards = []
        message_rewards = []
        missions_completed = 0
        new_mission_reward = None

        if user_id:
            streak = update_streak(user_id)
            rewards = check_streak_rewards(user_id, streak)
            message_rewards = check_message_rewards(user_id)

        # âœ… Mission tracking if replying
        if reply_to and user_id:
            try:
                with open("daily_tasks.json") as f:
                    tasks = json.load(f)
                task_to_complete = next(
                    (t for t in tasks if t.get("task") == reply_to or str(t.get("timestamp")) == reply_to),
                    None
                )
                if task_to_complete:
                    save_completed_task(user_id, task_to_complete)

                    # Increment missions completed
                    progress = get_user_progress(user_id)
                    progress["missions_completed"] = progress.get("missions_completed", 0) + 1
                    missions_completed = progress["missions_completed"]

                    # Check mission milestone rewards
                    if missions_completed in MISSION_REWARDS:
                        reward = MISSION_REWARDS[missions_completed]
                        progress["xp"] += reward["xp"]
                        if reward["badge"] not in progress.get("badges", []):
                            progress["badges"].append(reward["badge"])
                        new_mission_reward = reward
                    save_user_progress(user_id, progress)
            except Exception as e:
                print("âš  Error marking growth prompt complete:", e)

        # Save incoming user message to Firestore (memory) if user_id exists
        if user_id:
            try:
                # Save the raw incoming user entry as a 'user' role
                save_conversation_message(user_id, "user", entry)
            except Exception as e:
                print("âš  Warning: could not save incoming message:", e)

        # Build context messages for OpenAI
        messages_for_ai = []
        # add a short system persona message (keeps behaviour consistent)
        system_msg = {
            "role": "system",
            "content": "You are a kind, reflective Spiral Dynamics mentor and supportive chatbot for RETVRN. Keep replies concise and empathetic."
        }
        messages_for_ai.append(system_msg)

        # If we have a user_id, fetch recent messages and append
        if user_id:
            try:
                recent = get_recent_conversation(user_id, limit=HISTORY_LIMIT)
                # recent is oldest->newest
                for m in recent:
                    # Ensure role conforms to OpenAI roles
                    r = m.get("role", "user")
                    if r not in ("user", "assistant", "system"):
                        r = "user"
                    messages_for_ai.append({"role": r, "content": m.get("content", "")})
            except Exception as e:
                print("âš  Could not fetch recent conversation:", e)

        # Append the current user message last
        current_user_content = entry if not reply_to else f"Previous: {reply_to}\nUser: {entry}"
        messages_for_ai.append({"role": "user", "content": current_user_content})

        # Decide intent
        intent = detect_intent(entry)

        # ---------------------------
        # Chat (casual) flow
        # ---------------------------
        if intent == "chat":
            try:
                resp = client.chat.completions.create(
                    model='gpt-4.1',
                    messages=messages_for_ai,
                    temperature=0.7,
                )
                ai_resp = resp.choices[0].message.content.strip()
            except Exception as e:
                print("AI chat error, falling back:", e)
                try:
                    # fallback simple call without history
                    ai_resp = client.chat.completions.create(
                        model='gpt-4.1',
                        messages=[{"role": "user", "content": f"Be a kind friend and casually respond to:\n{current_user_content}"}],
                        temperature=0.7
                    ).choices[0].message.content.strip()
                except Exception as e2:
                    print("Fallback AI also failed:", e2)
                    return jsonify({"error": "AI service unavailable"}), 503

            # Save assistant response to Firestore
            if user_id:
                try:
                    save_conversation_message(user_id, "assistant", ai_resp)
                except Exception as e:
                    print("âš  Could not save assistant reply:", e)

            return jsonify({
                "mode": "chat",
                "response": ai_resp,
                "streak": streak,
                "rewards": rewards,
                "message_rewards": message_rewards,
                "missions_completed": missions_completed,
                "new_mission_reward": new_mission_reward,
            })

        # ---------------------------
        # Spiral (reflection) flow
        # ---------------------------
        # Provide a small context string to pass to classifier & question generator
        context_text = ""
        if user_id:
            try:
                recent_small = get_recent_conversation(user_id, limit=3)
                context_text = "\n".join([f"{m['role']}: {m['content']}" for m in recent_small])
            except Exception:
                context_text = ""

        # Pass context into classify_stage (we adjusted signature to accept optional context)
        try:
            classification = classify_stage(entry, context=context_text)
        except TypeError:
            # back-compat: if classify_stage doesn't accept context, call old way
            classification = classify_stage(entry)

        stage = classification.get("stage")
        evolution_msg = check_evolution(last_stage, classification)

        xp_gain = 0
        badges = []
        if user_id and evolution_msg:
            progress = get_user_progress(user_id)
            progress["xp"] += XP_REWARDS.get("level_up", 10)
            if "level_up" not in progress.get("badges", []):
                progress["badges"].append("level_up")
                badges.append("ðŸŒ± Level Up")
            save_user_progress(user_id, progress)
            xp_gain = XP_REWARDS.get("level_up", 10)

        gamified = generate_gamified_prompt(stage or last_stage, entry, evolution=bool(evolution_msg))

        # generate_reflective_question now may accept context as second arg (back-compat handled)
        try:
            question = generate_reflective_question(entry, reply_to=reply_to or None, context=context_text)
        except TypeError:
            question = generate_reflective_question(entry, reply_to)

        # Save assistant-generated question (assistant message) into conversation store
        if user_id and question:
            try:
                save_conversation_message(user_id, "assistant", question)
            except Exception as e:
                print("âš  Could not save assistant question:", e)

        response = {
            "mode": "spiral",
            "stage": stage,
            "evolution": evolution_msg,
            "xp_gain": xp_gain,
            "badges": badges,
            "question": question,
            "gamified": gamified,
            "confidence": classification.get("confidence"),
            "reason": classification.get("reason"),
            "streak": streak,
            "rewards": rewards,
            "message_rewards": message_rewards,
            "missions_completed": missions_completed,
            "new_mission_reward": new_mission_reward,
        }
        if classification.get("confidence", 1) < 0.7 and classification.get("secondary"):
            response["note"] = f"Also detected: {classification['secondary']}"
        return jsonify(response)

    except Exception:
        traceback.print_exc()
        return jsonify({"error": "Failed to process reflection"}), 500


@bp.route('/reflect_transcription', methods=['POST'])
def reflect_transcription():
    try:
        if 'audio' not in request.files:
            return jsonify({"error": "Missing audio file"}), 400
        reply_to = request.form.get("reply_to", "")
        last_stage = request.form.get("last_stage", "")
        user_id = request.form.get("user_id", "")
        audio_file = request.files['audio']

        streak = 0
        rewards = []
        message_rewards = []
        missions_completed = 0
        new_mission_reward = None

        if user_id:
            streak = update_streak(user_id)
            rewards = check_streak_rewards(user_id, streak)
            message_rewards = check_message_rewards(user_id)

        # âœ… Mission tracking if replying (audio)
        if reply_to and user_id:
            try:
                with open("daily_tasks.json") as f:
                    tasks = json.load(f)
                task_to_complete = next(
                    (t for t in tasks if t.get("task") == reply_to or str(t.get("timestamp")) == reply_to),
                    None
                )
                if task_to_complete:
                    save_completed_task(user_id, task_to_complete)

                    # Increment missions completed
                    progress = get_user_progress(user_id)
                    progress["missions_completed"] = progress.get("missions_completed", 0) + 1
                    missions_completed = progress["missions_completed"]

                    # Check mission milestone rewards
                    if missions_completed in MISSION_REWARDS:
                        reward = MISSION_REWARDS[missions_completed]
                        progress["xp"] += reward["xp"]
                        if reward["badge"] not in progress.get("badges", []):
                            progress["badges"].append(reward["badge"])
                        new_mission_reward = reward
                    save_user_progress(user_id, progress)
            except Exception as e:
                print("âš  Error marking growth prompt complete (audio):", e)

        filename = f"{user_id or 'anon'}_{datetime.utcnow().strftime('%Y%m%d%H%M%S')}.wav"
        os.makedirs("audios", exist_ok=True)
        path = os.path.join("audios", filename)
        audio_file.save(path)

        upload_resp = requests.post(
            "https://api.assemblyai.com/v2/upload",
            headers={"authorization": os.getenv("ASSEMBLYAI_API_KEY"), "content-type": "application/octet-stream"},
            data=open(path, "rb")
        )
        audio_url = upload_resp.json().get("upload_url")
        transcript_post = requests.post(
            "https://api.assemblyai.com/v2/transcript",
            headers={"authorization": os.getenv("ASSEMBLYAI_API_KEY")},
            json={"audio_url": audio_url, "speaker_labels": True}
        )
        transcript_id = transcript_post.json().get("id")

        while True:
            poll_resp = requests.get(
                f"https://api.assemblyai.com/v2/transcript/{transcript_id}",
                headers={"authorization": os.getenv("ASSEMBLYAI_API_KEY")},
            )
            poll_data = poll_resp.json()
            if poll_data.get("status") in ("completed", "error"):
                break

        if poll_data.get("status") == "error":
            return jsonify({"error": "Transcription failed"}), 500

        transcript_text = poll_data.get("text", "")
        utterances = poll_data.get("utterances", [])
        dialogue = "\n".join(f"Speaker {u['speaker']}: {u['text']}" for u in utterances)

        intent = detect_intent(transcript_text)
        if intent == "chat":
            ai_resp = client.chat.completions.create(
                model='gpt-4.1',
                messages=[{"role": "user", "content": f"Carefully respond to:\n{dialogue}"}],
                temperature=0.7,
            ).choices[0].message.content.strip()
            return jsonify({
                "mode": "chat",
                "response": ai_resp,
                "transcription": dialogue,
                "diarized": True,
                "streak": streak,
                "rewards": rewards,
                "message_rewards": message_rewards,
                "missions_completed": missions_completed,
                "new_mission_reward": new_mission_reward,
            })

        speaker_texts = defaultdict(str)
        for u in utterances:
            speaker_name = f"Speaker {u['speaker']}"
            speaker_texts[speaker_name] += u["text"] + " "

        speaker_stages = {}
        for speaker_name, text in speaker_texts.items():
            try:
                stage_info = classify_stage(text.strip())
                speaker_stages[speaker_name] = {"stage": stage_info["stage"], "text": text.strip()}
            except Exception as e:
                speaker_stages[speaker_name] = {"stage": "Unknown", "text": text.strip(), "error": str(e)}

        return jsonify({
            "mode": "spiral",
            "transcription": dialogue,
            "speaker_stages": speaker_stages,
            "diarized": True,
            "ask_speaker_pick": True,
            "streak": streak,
            "rewards": rewards,
            "message_rewards": message_rewards,
            "missions_completed": missions_completed,
            "new_mission_reward": new_mission_reward,
        })
    except Exception:
        traceback.print_exc()
        return jsonify({"error": "Failed to process transcription"}), 500


@bp.route('/finalize_stage', methods=['POST'])
def finalize_stage():
    try:
        data = request.json
        speaker_id = data.get("speaker_id")
        speaker_stages = data.get("speaker_stages", {})
        last_stage = data.get("last_stage", "")
        reply_to = data.get("reply_to", "")
        user_id = data.get("user_id")

        if speaker_id not in speaker_stages:
            return jsonify({"error": "Speaker not found"}), 400

        speaker_info = speaker_stages[speaker_id]
        current_stage = speaker_info.get("stage", "Unknown")
        text = speaker_info.get("text", "")
        evolution_msg = check_evolution(last_stage, {"stage": current_stage})

        xp_gain = 0
        badges = []
        if user_id and evolution_msg:
            progress = get_user_progress(user_id)
            progress["xp"] += XP_REWARDS.get("level_up", 10)
            if "level_up" not in progress.get("badges", []):
                progress["badges"].append("level_up")
                badges.append("ðŸŒ± Level Up")
            save_user_progress(user_id, progress)
            xp_gain = XP_REWARDS.get("level_up", 10)

        gamified = generate_gamified_prompt(current_stage, text, evolution=bool(evolution_msg))
        question = generate_reflective_question(text, reply_to)

        return jsonify({
            "stage": current_stage,
            "question": question,
            "evolution": evolution_msg,
            "gamified": gamified,
            "xp_gain": xp_gain,
            "badges": badges,
        })
    except Exception:
        traceback.print_exc()
        return jsonify({"error": "Failed to finalize stage"}), 500



firebase_utils.py:
py
import time
import traceback
import firebase_admin
from firebase_admin import credentials, firestore
from config import FIREBASE_CONFIG

def init_firebase():
    """
    Initialize Firebase app and Firestore client.
    Returns the Firestore client instance or None if initialization fails.
    """
    try:
        # Initialize Firebase app with service account credentials
        cred = credentials.Certificate(FIREBASE_CONFIG)
        if not firebase_admin._apps:
            firebase_admin.initialize_app(cred)
        db = firestore.client()
        return db
    except Exception as e:
        print(f"Firebase initialization failed: {e}")
        return None

# Initialize Firestore client at module load
db = init_firebase()


# ------------------------
# Conversation memory helpers
# ------------------------

def save_conversation_message(user_id: str, role: str, content: str, timestamp: int = None) -> bool:
    """
    Save a single conversation message for a user into Firestore.
    Collection path: conversations/{user_id}/messages/{timestamp_doc}
    role: 'user' | 'assistant' | 'system'
    content: message text
    timestamp: epoch ms, optional (generated if not provided)
    Returns True on success, False on failure.
    """
    try:
        if db is None:
            print("Firestore db not initialized - cannot save message.")
            return False
        if timestamp is None:
            timestamp = int(time.time() * 1000)
        # Use timestamp as document id to keep ordering and avoid duplicates
        doc_ref = db.collection("conversations").document(str(user_id)).collection("messages").document(str(timestamp))
        payload = {
            "role": role,
            "content": content,
            "ts": timestamp
        }
        doc_ref.set(payload)
        return True
    except Exception as e:
        print("Error saving conversation message:", e)
        traceback.print_exc()
        return False


def get_recent_conversation(user_id: str, limit: int = 6):
    """
    Return a list of recent messages for a user ordered oldest->newest.
    Each item is a dict: {"role": "...", "content": "...", "ts": ...}
    If db not initialized or error, returns [].
    """
    try:
        if db is None:
            print("Firestore db not initialized - cannot fetch messages.")
            return []
        coll = db.collection("conversations").document(str(user_id)).collection("messages")
        # Query most recent first, then reverse to get oldest->newest
        docs = coll.order_by("ts", direction=firestore.Query.DESCENDING).limit(limit).stream()
        msgs = []
        for d in docs:
            data = d.to_dict()
            msgs.append({
                "role": data.get("role", "user"),
                "content": data.get("content", ""),
                "ts": data.get("ts", 0)
            })
        msgs.reverse()
        return msgs
    except Exception as e:
        print("Error fetching recent conversation:", e)
        traceback.print_exc()
        return []
