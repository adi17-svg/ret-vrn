
# # # New working
# from flask import Flask, request, jsonify
# from flask_cors import CORS
# from openai import OpenAI
# from dotenv import load_dotenv
# import os
# import traceback

# load_dotenv()
# a4f_api_key = os.getenv("A4F_API_KEY")
# if not a4f_api_key:
#     raise ValueError("âŒ A4F_API_KEY not found in .env")

# client = OpenAI(api_key=a4f_api_key, base_url="https://api.a4f.co/v1")
# app = Flask(__name__)
# CORS(app)

# STAGES = ["Beige", "Purple", "Red", "Blue", "Orange", "Green", "Yellow", "Turquoise"]

# def detect_intent(entry):
#     prompt = (
#         "You are a gatekeeper. Is this journal entry about personal reflection, values, or growth (Spiral Dynamics)? "
#         "Or is it just casual talk?\n\n"
#         "Reply with one word only: 'spiral' or 'chat'.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = client.chat.completions.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0,
#     )
#     return "spiral" if "spiral" in response.choices[0].message.content.lower() else "chat"

# def classify_stage(entry):
#     prompt = (
#         f"Analyze the user's entry and return only the Spiral Dynamics stage (one of: {', '.join(STAGES)}). "
#         f"Respond only with the stage name.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = client.chat.completions.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.6,
#     )
#     return response.choices[0].message.content.strip()

# def generate_reflective_question(entry, reply_to=None):
#     context = f"\nReplying to: \"{reply_to}\"" if reply_to else ""
#     prompt = (
#         f"You are a Spiral Dynamics mentor. Based on the user's thoughts{context}, "
#         f"ask one deep, emotionally resonant question. "
#         f"Don't mention Spiral Dynamics. Don't explain anything. Just ask the question.\n\n"
#         f"User message: \"{entry}\""
#     )
#     response = client.chat.completions.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.85,
#     )
#     return response.choices[0].message.content.strip()

# def generate_growth_prompt(entry, stage):
#     prompt = (
#         f"User is currently reflecting at Spiral Dynamics stage: {stage}. "
#         f"Based on this short journal entry, give one brief nudge or thought that could help them evolve. "
#         f"Don't say it's a growth tip. Don't label it. Just give a sentence that feels natural and empowering.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = client.chat.completions.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.8,
#     )
#     return response.choices[0].message.content.strip()

# def check_evolution(last_stage, current_stage):
#     try:
#         if STAGES.index(current_stage) > STAGES.index(last_stage):
#             return f"ðŸŒ± Beautiful shift! You've evolved to {current_stage} â€” keep growing ðŸŒŸ"
#     except:
#         pass
#     return None

# @app.route("/merged", methods=["POST"])
# def merged_reflection():
#     try:
#         data = request.get_json()
#         entry = data.get("text", "").strip()
#         last_stage = data.get("last_stage", "").strip()
#         reply_to = data.get("reply_to", "").strip()

#         if not entry:
#             return jsonify({"error": "Missing journaling input."}), 400

#         intent = detect_intent(entry)

#         if intent == "chat":
#             message = f"User: {reply_to}\n\nUser response: {entry}" if reply_to else entry
#             reply = client.chat.completions.create(
#                 model="provider-3/gpt-4o",
#                 messages=[{"role": "user", "content": f"You are a kind friend. Respond casually to: {message}"}],
#                 temperature=0.7,
#             )
#             return jsonify({
#                 "mode": "chat",
#                 "response": reply.choices[0].message.content.strip()
#             })

#         # spiral mode
#         stage = classify_stage(entry)
#         question = generate_reflective_question(entry, reply_to)
#         evolution_msg = check_evolution(last_stage, stage)
#         growth = generate_growth_prompt(entry, stage)

#         return jsonify({
#             "mode": "spiral",
#             "stage": stage,
#             "question": question,
#             "evolution": evolution_msg,
#             "growth": growth
#         })

#     except Exception as e:
#         traceback.print_exc()
#         return jsonify({"error": str(e)}), 500

# if __name__ == "__main__":
#     app.run(debug=True, host="0.0.0.0", port=5000)


# chat working
# from flask import Flask, request, jsonify
# from flask_cors import CORS
# from openai import OpenAI
# from dotenv import load_dotenv
# import os
# import traceback

# # Load environment
# load_dotenv()
# a4f_api_key = os.getenv("A4F_API_KEY")
# openai_key = os.getenv("OPENAI_API_KEY")

# if not a4f_api_key or not openai_key:
#     raise ValueError("âŒ A4F_API_KEY or OPENAI_API_KEY not found in .env")

# client = OpenAI(api_key=a4f_api_key, base_url="https://api.a4f.co/v1")
# oa_client = OpenAI(api_key=openai_key)

# app = Flask(__name__)
# CORS(app)

# STAGES = ["Beige", "Purple", "Red", "Blue", "Orange", "Green", "Yellow", "Turquoise"]

# ##################################
# # ðŸ”® Spiral Core Functions
# ##################################

# def detect_intent(entry):
#     prompt = (
#         "You are a gatekeeper. Is this journal entry about personal reflection, values, or growth (Spiral Dynamics)? "
#         "Or is it just casual talk?\n\n"
#         "Reply with one word only: 'spiral' or 'chat'.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = client.chat.completions.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0,
#     )
#     return "spiral" if "spiral" in response.choices[0].message.content.lower() else "chat"

# def classify_stage(entry):
#     prompt = (
#         f"Analyze the user's entry and return only the Spiral Dynamics stage (one of: {', '.join(STAGES)}). "
#         f"Respond only with the stage name.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = client.chat.completions.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.6,
#     )
#     return response.choices[0].message.content.strip()

# def generate_reflective_question(entry, reply_to=None):
#     context = f"\nReplying to: \"{reply_to}\"" if reply_to else ""
#     prompt = (
#         f"You are a Spiral Dynamics mentor. Based on the user's thoughts{context}, "
#         f"ask one deep, emotionally resonant question. "
#         f"Don't mention Spiral Dynamics. Don't explain anything. Just ask the question.\n\n"
#         f"User message: \"{entry}\""
#     )
#     response = client.chat.completions.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.85,
#     )
#     return response.choices[0].message.content.strip()

# def generate_growth_prompt(entry, stage):
#     prompt = (
#         f"User is currently reflecting at Spiral Dynamics stage: {stage}. "
#         f"Based on this short journal entry, give one brief nudge or thought that could help them evolve. "
#         f"Don't say it's a growth tip. Don't label it. Just give a sentence that feels natural and empowering.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = client.chat.completions.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.8,
#     )
#     return response.choices[0].message.content.strip()

# def check_evolution(last_stage, current_stage):
#     try:
#         if STAGES.index(current_stage) > STAGES.index(last_stage):
#             return f"ðŸŒ± Beautiful shift! You've evolved to {current_stage} â€” keep growing ðŸŒŸ"
#     except:
#         pass
#     return None

# ##################################
# # ðŸ§  Text-based Reflection
# ##################################

# @app.route("/merged", methods=["POST"])
# def merged_reflection():
#     try:
#         data = request.get_json()
#         entry = data.get("text", "").strip()
#         last_stage = data.get("last_stage", "").strip()
#         reply_to = data.get("reply_to", "").strip()

#         if not entry:
#             return jsonify({"error": "Missing journaling input."}), 400

#         intent = detect_intent(entry)

#         if intent == "chat":
#             message = f"User: {reply_to}\n\nUser response: {entry}" if reply_to else entry
#             reply = client.chat.completions.create(
#                 model="provider-3/gpt-4o",
#                 messages=[{"role": "user", "content": f"You are a kind friend. Respond casually to: {message}"}],
#                 temperature=0.7,
#             )
#             return jsonify({
#                 "mode": "chat",
#                 "response": reply.choices[0].message.content.strip()
#             })

#         stage = classify_stage(entry)
#         question = generate_reflective_question(entry, reply_to)
#         evolution_msg = check_evolution(last_stage, stage)
#         growth = generate_growth_prompt(entry, stage)

#         return jsonify({
#             "mode": "spiral",
#             "stage": stage,
#             "question": question,
#             "evolution": evolution_msg,
#             "growth": growth
#         })

#     except Exception as e:
#         traceback.print_exc()
#         return jsonify({"error": str(e)}), 500

# ##################################
# # ðŸ”Š Voice-based Reflection
# ##################################

# @app.route("/transcribe_audio", methods=["POST"])
# def transcribe_and_reflect():
#     try:
#         if "file" not in request.files:
#             return jsonify({"error": "No audio file provided"}), 400

#         audio_file = request.files["file"]

#         whisper_response = oa_client.audio.transcriptions.create(
#             model="whisper-1",
#             file=(audio_file.filename, audio_file.stream, audio_file.mimetype)
#         )

#         transcript = whisper_response.text.strip()
#         print(f"ðŸŽ¤ Transcript: {transcript}")

#         # Proceed to Spiral logic
#         intent = detect_intent(transcript)

#         if intent == "chat":
#             reply = client.chat.completions.create(
#                 model="provider-3/gpt-4o",
#                 messages=[{"role": "user", "content": f"You are a kind friend. Respond casually to: {transcript}"}],
#                 temperature=0.7,
#             )
#             return jsonify({
#                 "mode": "chat",
#                 "transcription": transcript,
#                 "response": reply.choices[0].message.content.strip()
#             })

#         stage = classify_stage(transcript)
#         question = generate_reflective_question(transcript)
#         growth = generate_growth_prompt(transcript, stage)

#         return jsonify({
#             "mode": "spiral",
#             "transcription": transcript,
#             "stage": stage,
#             "question": question,
#             "growth": growth
#         })

#     except Exception as e:
#         traceback.print_exc()
#         return jsonify({"error": str(e)}), 500

# ##################################
# # Run Server
# ##################################

# if __name__ == "__main__":
#     app.run(debug=True, host="0.0.0.0", port=5000)










# from flask import Flask, request, jsonify
# from flask_cors import CORS
# from openai import OpenAI
# from dotenv import load_dotenv
# import os
# import whisper
# import traceback
# # Setup
# load_dotenv()
# a4f_api_key = os.getenv("A4F_API_KEY")
# if not a4f_api_key:
#     raise ValueError("âŒ A4F_API_KEY not found in .env")

# client = OpenAI(api_key=a4f_api_key, base_url="https://api.a4f.co/v1")

# app = Flask(__name__)
# CORS(app)

# whisper_model = whisper.load_model("base")
# STAGES = ["Beige", "Purple", "Red", "Blue", "Orange", "Green", "Yellow", "Turquoise"]

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Spiral Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
# def detect_intent(entry):
#     prompt = (
#         "You are a gatekeeper. Is this journal entry about personal reflection, values, or growth (Spiral Dynamics)? "
#         "Or is it just casual talk?\n\n"
#         "Reply with one word only: 'spiral' or 'chat'.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = client.chat.completions.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0,
#     )
#     return "spiral" if "spiral" in response.choices[0].message.content.lower() else "chat"

# def classify_stage(entry):
#     prompt = (
#         f"Analyze the user's entry and return only the Spiral Dynamics stage (one of: {', '.join(STAGES)}). "
#         f"Respond only with the stage name.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = client.chat.completions.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.6,
#     )
#     return response.choices[0].message.content.strip()

# def generate_reflective_question(entry, reply_to=None):
#     context = f"\nReplying to: \"{reply_to}\"" if reply_to else ""
#     prompt = (
#         f"You are a Spiral Dynamics mentor. Based on the user's thoughts{context}, "
#         f"ask one deep, emotionally resonant question. "
#         f"Don't mention Spiral Dynamics. Don't explain anything. Just ask the question.\n\n"
#         f"User message: \"{entry}\""
#     )
#     response = client.chat.completions.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.85,
#     )
#     return response.choices[0].message.content.strip()

# def generate_growth_prompt(entry, stage):
#     prompt = (
#         f"User is currently reflecting at Spiral Dynamics stage: {stage}. "
#         f"Based on this short journal entry, give one brief nudge or thought that could help them evolve. "
#         f"Don't say it's a growth tip. Don't label it. Just give a sentence that feels natural and empowering.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = client.chat.completions.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.8,
#     )
#     return response.choices[0].message.content.strip()

# def check_evolution(last_stage, current_stage):
#     try:
#         if STAGES.index(current_stage) > STAGES.index(last_stage):
#             return f"ðŸŒ± Beautiful shift! You've evolved to {current_stage} â€” keep growing ðŸŒŸ"
#     except:
#         pass
#     return None

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Combined Whisper + GPT Route â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
# @app.route("/reflect_transcription", methods=["POST"])
# def reflect_from_audio():
#     try:
#         if "file" not in request.files:
#             return jsonify({"error": "Missing audio file"}), 400

#         audio_file = request.files["file"]
#         last_stage = request.form.get("last_stage", "")
#         reply_to = request.form.get("reply_to", "")

#         # Save temp file
#         temp_path = "temp_audio.wav"
#         audio_file.save(temp_path)

#         # Whisper transcription
#         result = whisper_model.transcribe(temp_path)
#         entry = result["text"].strip()

#         os.remove(temp_path)  # clean up

#         if not entry:
#             return jsonify({"error": "No speech detected."}), 400

#         # Intent check
#         intent = detect_intent(entry)
#         if intent == "chat":
#             reply = client.chat.completions.create(
#                 model="provider-3/gpt-4o",
#                 messages=[{
#                     "role": "user",
#                     "content": f"You are a kind friend. Respond casually to: {entry}"
#                 }],
#                 temperature=0.7,
#             )
#             return jsonify({
#                 "mode": "chat",
#                 "transcription": entry,
#                 "response": reply.choices[0].message.content.strip()
#             })

#         # Spiral mode
#         stage = classify_stage(entry)
#         question = generate_reflective_question(entry, reply_to)
#         evolution = check_evolution(last_stage, stage)
#         growth = generate_growth_prompt(entry, stage)

#         return jsonify({
#             "mode": "spiral",
#             "transcription": entry,
#             "stage": stage,
#             "question": question,
#             "growth": growth,
#             "evolution": evolution
#         })

#     except Exception as e:
#         traceback.print_exc()
#         return jsonify({"error": str(e)}), 500

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Server Run â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
# if __name__ == "__main__":
#     app.run(debug=True, host="0.0.0.0", port=5000)


# Merged working both 
# from flask import Flask, request, jsonify
# from flask_cors import CORS
# from dotenv import load_dotenv
# import os
# import openai  # LEGACY SDK
# import whisper
# import traceback

# # Load environment variables
# load_dotenv()
# a4f_api_key = os.getenv("A4F_API_KEY")
# if not a4f_api_key:
#     raise ValueError("âŒ A4F_API_KEY not found in .env")

# # Setup A4F GPT-compatible client using legacy OpenAI SDK
# openai.api_key = a4f_api_key
# openai.api_base = "https://api.a4f.co/v1"

# whisper_model = whisper.load_model("base")

# app = Flask(__name__)
# CORS(app)

# STAGES = ["Beige", "Purple", "Red", "Blue", "Orange", "Green", "Yellow", "Turquoise"]

# # Core Functions
# def detect_intent(entry):
#     prompt = (
#         "You are a gatekeeper. Is this journal entry about personal reflection, values, or growth (Spiral Dynamics)? "
#         "Or is it just casual talk?\n\n"
#         "Reply with one word only: 'spiral' or 'chat'.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0,
#     )
#     return "spiral" if "spiral" in response.choices[0].message["content"].lower() else "chat"

# def classify_stage(entry):
#     prompt = (
#         f"Analyze the user's entry and return only the Spiral Dynamics stage (one of: {', '.join(STAGES)}). "
#         f"Respond only with the stage name.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.6,
#     )
#     return response.choices[0].message["content"].strip()

# def generate_reflective_question(entry, reply_to=None):
#     context = f"\nReplying to: \"{reply_to}\"" if reply_to else ""
#     prompt = (
#         f"You are a Spiral Dynamics mentor. Based on the user's thoughts{context}, "
#         f"ask one deep, emotionally resonant question. "
#         f"Don't mention Spiral Dynamics. Don't explain anything. Just ask the question.\n\n"
#         f"User message: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.85,
#     )
#     return response.choices[0].message["content"].strip()

# def generate_growth_prompt(entry, stage):
#     prompt = (
#         f"User is currently reflecting at Spiral Dynamics stage: {stage}. "
#         f"Based on this short journal entry, give one brief nudge or thought that could help them evolve. "
#         f"Don't say it's a growth tip. Don't label it. Just give a sentence that feels natural and empowering.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.8,
#     )
#     return response.choices[0].message["content"].strip()

# def check_evolution(last_stage, current_stage):
#     try:
#         if STAGES.index(current_stage) > STAGES.index(last_stage):
#             return f"ðŸŒ± Beautiful shift! You've evolved to {current_stage} â€” keep growing ðŸŒŸ"
#     except:
#         pass
#     return None

# # TEXT endpoint
# @app.route("/merged", methods=["POST"])
# def merged_reflection():
#     try:
#         data = request.get_json()
#         entry = data.get("text", "").strip()
#         last_stage = data.get("last_stage", "").strip()
#         reply_to = data.get("reply_to", "").strip()

#         if not entry:
#             return jsonify({"error": "Missing journaling input."}), 400

#         intent = detect_intent(entry)

#         if intent == "chat":
#             message = f"User: {reply_to}\n\nUser response: {entry}" if reply_to else entry
#             reply = openai.ChatCompletion.create(
#                 model="provider-3/gpt-4o",
#                 messages=[{"role": "user", "content": f"You are a kind friend. Respond casually to: {message}"}],
#                 temperature=0.7,
#             )
#             return jsonify({
#                 "mode": "chat",
#                 "response": reply.choices[0].message["content"].strip()
#             })

#         stage = classify_stage(entry)
#         question = generate_reflective_question(entry, reply_to)
#         evolution_msg = check_evolution(last_stage, stage)
#         growth = generate_growth_prompt(entry, stage)

#         return jsonify({
#             "mode": "spiral",
#             "stage": stage,
#             "question": question,
#             "evolution": evolution_msg,
#             "growth": growth
#         })

#     except Exception as e:
#         traceback.print_exc()
#         return jsonify({"error": str(e)}), 500

# # AUDIO endpoint (offline Whisper)
# @app.route("/reflect_transcription", methods=["POST"])
# def reflect_from_audio():
#     try:
#         if "file" not in request.files:
#             return jsonify({"error": "Missing audio file"}), 400

#         audio_file = request.files["file"]
#         last_stage = request.form.get("last_stage", "")
#         reply_to = request.form.get("reply_to", "")

#         temp_path = "temp_audio.wav"
#         audio_file.save(temp_path)

#         result = whisper_model.transcribe(temp_path)
#         entry = result["text"].strip()
#         os.remove(temp_path)

#         if not entry:
#             return jsonify({"error": "No speech detected."}), 400

#         intent = detect_intent(entry)

#         if intent == "chat":
#             reply = openai.ChatCompletion.create(
#                 model="provider-3/gpt-4o",
#                 messages=[{"role": "user", "content": f"You are a kind friend. Respond casually to: {entry}"}],
#                 temperature=0.7,
#             )
#             return jsonify({
#                 "mode": "chat",
#                 "transcription": entry,
#                 "response": reply.choices[0].message["content"].strip()
#             })

#         stage = classify_stage(entry)
#         question = generate_reflective_question(entry, reply_to)
#         evolution = check_evolution(last_stage, stage)
#         growth = generate_growth_prompt(entry, stage)

#         return jsonify({
#             "mode": "spiral",
#             "transcription": entry,
#             "stage": stage,
#             "question": question,
#             "growth": growth,
#             "evolution": evolution
#         })

#     except Exception as e:
#         traceback.print_exc()
#         return jsonify({"error": str(e)}), 500

# # Run server

# # Run server
# if __name__ == "__main__":
#     app.run(debug=True, host="0.0.0.0", port=5000)


# Transcription working with other models
# from flask import Flask, request, jsonify
# from flask_cors import CORS
# from dotenv import load_dotenv
# import os
# import openai  # LEGACY SDK
# import traceback
# import requests

# # Load environment variables
# load_dotenv()
# a4f_api_key = os.getenv("A4F_API_KEY")
# assemblyai_api_key = os.getenv("ASSEMBLYAI_API_KEY")

# if not a4f_api_key or not assemblyai_api_key:
#     raise ValueError("âŒ Missing A4F or AssemblyAI API key in .env")

# # Setup A4F GPT-compatible client using legacy OpenAI SDK
# openai.api_key = a4f_api_key
# openai.api_base = "https://api.a4f.co/v1"

# app = Flask(__name__)
# CORS(app)

# STAGES = ["Beige", "Purple", "Red", "Blue", "Orange", "Green", "Yellow", "Turquoise"]

# # Core Functions
# def detect_intent(entry):
#     prompt = (
#         "You are a gatekeeper. Is this journal entry about personal reflection, values, or growth (Spiral Dynamics)? "
#         "Or is it just casual talk?\n\n"
#         "Reply with one word only: 'spiral' or 'chat'.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0,
#     )
#     return "spiral" if "spiral" in response.choices[0].message["content"].lower() else "chat"

# def classify_stage(entry):
#     prompt = (
#         f"Analyze the user's entry and return only the Spiral Dynamics stage (one of: {', '.join(STAGES)}). "
#         f"Respond only with the stage name.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.6,
#     )
#     return response.choices[0].message["content"].strip()

# def generate_reflective_question(entry, reply_to=None):
#     context = f"\nReplying to: \"{reply_to}\"" if reply_to else ""
#     prompt = (
#         f"You are a Spiral Dynamics mentor. Based on the user's thoughts{context}, "
#         f"ask one deep, emotionally resonant question. "
#         f"Don't mention Spiral Dynamics. Don't explain anything. Just ask the question.\n\n"
#         f"User message: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.85,
#     )
#     return response.choices[0].message["content"].strip()

# def generate_growth_prompt(entry, stage):
#     prompt = (
#         f"User is currently reflecting at Spiral Dynamics stage: {stage}. "
#         f"Based on this short journal entry, give one brief nudge or thought that could help them evolve. "
#         f"Don't say it's a growth tip. Don't label it. Just give a sentence that feels natural and empowering.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.8,
#     )
#     return response.choices[0].message["content"].strip()

# def check_evolution(last_stage, current_stage):
#     try:
#         if STAGES.index(current_stage) > STAGES.index(last_stage):
#             return f"ðŸŒ± Beautiful shift! You've evolved to {current_stage} â€” keep growing ðŸŒŸ"
#     except:
#         pass
#     return None

# # TEXT endpoint
# @app.route("/merged", methods=["POST"])
# def merged_reflection():
#     try:
#         data = request.get_json()
#         entry = data.get("text", "").strip()
#         last_stage = data.get("last_stage", "").strip()
#         reply_to = data.get("reply_to", "").strip()

#         if not entry:
#             return jsonify({"error": "Missing journaling input."}), 400

#         intent = detect_intent(entry)

#         if intent == "chat":
#             message = f"User: {reply_to}\n\nUser response: {entry}" if reply_to else entry
#             reply = openai.ChatCompletion.create(
#                 model="provider-3/gpt-4o",
#                 messages=[{"role": "user", "content": f"You are a kind friend. Respond casually to: {message}"}],
#                 temperature=0.7,
#             )
#             return jsonify({
#                 "mode": "chat",
#                 "response": reply.choices[0].message["content"].strip()
#             })

#         stage = classify_stage(entry)
#         question = generate_reflective_question(entry, reply_to)
#         evolution_msg = check_evolution(last_stage, stage)
#         growth = generate_growth_prompt(entry, stage)

#         return jsonify({
#             "mode": "spiral",
#             "stage": stage,
#             "question": question,
#             "evolution": evolution_msg,
#             "growth": growth
#         })

#     except Exception as e:
#         traceback.print_exc()
#         return jsonify({"error": str(e)}), 500

# # AUDIO endpoint
# @app.route("/reflect_transcription", methods=["POST"])
# def reflect_from_audio():
#     try:
#         if "file" not in request.files:
#             return jsonify({"error": "Missing audio file"}), 400

#         audio_file = request.files["file"]

#         # Step 1: Upload to AssemblyAI (as raw binary)
#         upload_response = requests.post(
#             "https://api.assemblyai.com/v2/upload",
#             headers={
#                 "authorization": assemblyai_api_key,
#                 "content-type": "application/octet-stream"
#             },
#             data=audio_file.read()
#         )
#         upload_response.raise_for_status()
#         audio_url = upload_response.json()["upload_url"]

#         # Step 2: Start transcription with speaker diarization
#         transcript_response = requests.post(
#             "https://api.assemblyai.com/v2/transcript",
#             headers={
#                 "authorization": assemblyai_api_key,
#                 "content-type": "application/json"
#             },
#             json={
#                 "audio_url": audio_url,
#                 "speaker_labels": True,
#                 "language_code": "en_us"
#             }
#         )
#         transcript_response.raise_for_status()
#         transcript_id = transcript_response.json()["id"]

#         # Step 3: Poll until transcription completes
#         while True:
#             poll = requests.get(
#                 f"https://api.assemblyai.com/v2/transcript/{transcript_id}",
#                 headers={"authorization": assemblyai_api_key}
#             )
#             result = poll.json()
#             if result["status"] in ("completed", "error"):
#                 break

#         if result["status"] == "error":
#             return jsonify({"error": f"Transcription failed: {result.get('error')}"}), 500

#         # Step 4: Return diarized transcript
#         # Step 4: Return diarized transcript
#         utterances = result.get("utterances", [])
#         if utterances and len(set(u["speaker"] for u in utterances)) > 1:
#             transcript = "\n".join([f"Speaker {u['speaker']}: {u['text']}" for u in utterances])
#         else:
#             transcript = result.get("text", "")

#         return jsonify({
#             "transcription": transcript,
#             "utterances": utterances  # ðŸ‘ˆ Return full diarized segments
#         })

#         # utterances = result.get("utterances", [])
#         # if utterances and len(set(u["speaker"] for u in utterances)) > 1:
#         #     transcript = "\n".join([f"Speaker {u['speaker']}: {u['text']}" for u in utterances])
#         # else:
#         #     transcript = result.get("text", "")

#         # return jsonify({
#         #     "transcription": transcript
#         # })
        

#     except Exception as e:
#         traceback.print_exc()
#         return jsonify({"error": str(e)}), 500


# # Run server
# if __name__ == "__main__":
#     app.run(debug=True, host="0.0.0.0", port=5000)


# Working spiral,transcription,diarization
# from flask import Flask, request, jsonify
# from flask_cors import CORS
# from dotenv import load_dotenv
# import os
# import openai  # LEGACY SDK
# import traceback
# import requests

# # Load environment variables
# load_dotenv()
# a4f_api_key = os.getenv("A4F_API_KEY")
# assemblyai_api_key = os.getenv("ASSEMBLYAI_API_KEY")

# if not a4f_api_key or not assemblyai_api_key:
#     raise ValueError("âŒ Missing A4F or AssemblyAI API key in .env")

# # Setup A4F GPT-compatible client using legacy OpenAI SDK
# openai.api_key = a4f_api_key
# openai.api_base = "https://api.a4f.co/v1"

# app = Flask(__name__)
# CORS(app)

# STAGES = ["Beige", "Purple", "Red", "Blue", "Orange", "Green", "Yellow", "Turquoise"]

# # Core Functions
# def detect_intent(entry):
#     prompt = (
#         "You are a gatekeeper. Is this journal entry about personal reflection, values, or growth (Spiral Dynamics)? "
#         "Or is it just casual talk?\n\n"
#         "Reply with one word only: 'spiral' or 'chat'.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0,
#     )
#     return "spiral" if "spiral" in response.choices[0].message["content"].lower() else "chat"

# def classify_stage(entry):
#     prompt = (
#         f"Analyze the user's entry and return only the Spiral Dynamics stage (one of: {', '.join(STAGES)}). "
#         f"Respond only with the stage name.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.6,
#     )
#     return response.choices[0].message["content"].strip()

# def generate_reflective_question(entry, reply_to=None):
#     context = f"\nReplying to: \"{reply_to}\"" if reply_to else ""
#     prompt = (
#         f"You are a Spiral Dynamics mentor. Based on the user's thoughts{context}, "
#         f"ask one deep, emotionally resonant question. "
#         f"Don't mention Spiral Dynamics. Don't explain anything. Just ask the question.\n\n"
#         f"User message: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.85,
#     )
#     return response.choices[0].message["content"].strip()

# def generate_growth_prompt(entry, stage):
#     prompt = (
#         f"User is currently reflecting at Spiral Dynamics stage: {stage}. "
#         f"Based on this short journal entry, give one brief nudge or thought that could help them evolve. "
#         f"Don't say it's a growth tip. Don't label it. Just give a sentence that feels natural and empowering.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.8,
#     )
#     return response.choices[0].message["content"].strip()

# def check_evolution(last_stage, current_stage):
#     try:
#         if STAGES.index(current_stage) > STAGES.index(last_stage):
#             return f"ðŸŒ± Beautiful shift! You've evolved to {current_stage} â€” keep growing ðŸŒŸ"
#     except:
#         pass
#     return None

# # TEXT endpoint
# @app.route("/merged", methods=["POST"])
# def merged_reflection():
#     try:
#         data = request.get_json()
#         entry = data.get("text", "").strip()
#         last_stage = data.get("last_stage", "").strip()
#         reply_to = data.get("reply_to", "").strip()

#         if not entry:
#             return jsonify({"error": "Missing journaling input."}), 400

#         intent = detect_intent(entry)

#         if intent == "chat":
#             message = f"User: {reply_to}\n\nUser response: {entry}" if reply_to else entry
#             reply = openai.ChatCompletion.create(
#                 model="provider-3/gpt-4o",
#                 messages=[{"role": "user", "content": f"You are a kind friend. Respond casually to: {message}"}],
#                 temperature=0.7,
#             )
#             return jsonify({
#                 "mode": "chat",
#                 "response": reply.choices[0].message["content"].strip()
#             })

#         stage = classify_stage(entry)
#         question = generate_reflective_question(entry, reply_to)
#         evolution_msg = check_evolution(last_stage, stage)
#         growth = generate_growth_prompt(entry, stage)

#         return jsonify({
#             "mode": "spiral",
#             "stage": stage,
#             "question": question,
#             "evolution": evolution_msg,
#             "growth": growth
#         })

#     except Exception as e:
#         traceback.print_exc()
#         return jsonify({"error": str(e)}), 500

# # AUDIO endpoint
# @app.route("/reflect_transcription", methods=["POST"])
# def reflect_from_audio():
#     try:
#         if "file" not in request.files:
#             return jsonify({"error": "Missing audio file"}), 400

#         audio_file = request.files["file"]

#         # Step 1: Upload to AssemblyAI (as raw binary)
#         upload_response = requests.post(
#             "https://api.assemblyai.com/v2/upload",
#             headers={
#                 "authorization": assemblyai_api_key,
#                 "content-type": "application/octet-stream"
#             },
#             data=audio_file.read()
#         )
#         upload_response.raise_for_status()
#         audio_url = upload_response.json()["upload_url"]

#         # Step 2: Start transcription with speaker diarization
#         transcript_response = requests.post(
#             "https://api.assemblyai.com/v2/transcript",
#             headers={
#                 "authorization": assemblyai_api_key,
#                 "content-type": "application/json"
#             },
#             json={
#                 "audio_url": audio_url,
#                 "speaker_labels": True,
#                 "language_code": "en_us"
#             }
#         )
#         transcript_response.raise_for_status()
#         transcript_id = transcript_response.json()["id"]

#         # Step 3: Poll until transcription completes
#         while True:
#             poll = requests.get(
#                 f"https://api.assemblyai.com/v2/transcript/{transcript_id}",
#                 headers={"authorization": assemblyai_api_key}
#             )
#             result = poll.json()
#             if result["status"] in ("completed", "error"):
#                 break

#         if result["status"] == "error":
#             return jsonify({"error": f"Transcription failed: {result.get('error')}"}), 500

#         utterances = result.get("utterances", [])
#         if utterances and len(set(u["speaker"] for u in utterances)) > 1:
#             transcript = "\n".join([f"Speaker {u['speaker']}: {u['text']}" for u in utterances])
#         else:
#             transcript = result.get("text", "")

#         # ðŸ§  Apply GPT logic to full transcript
#         entry = transcript.strip()
#         if not entry:
#             return jsonify({"error": "Transcription was empty."}), 400

#         intent = detect_intent(entry)

#         if intent == "chat":
#             reply = openai.ChatCompletion.create(
#                 model="provider-3/gpt-4o",
#                 messages=[{"role": "user", "content": f"You are a kind friend. Respond casually to: {entry}"}],
#                 temperature=0.7,
#             )
#             return jsonify({
#                 "mode": "chat",
#                 "response": reply.choices[0].message["content"].strip(),
#                 "transcription": transcript,
#                 "utterances": utterances
#             })

#         stage = classify_stage(entry)
#         question = generate_reflective_question(entry)
#         growth = generate_growth_prompt(entry, stage)

#         return jsonify({
#             "mode": "spiral",
#             "transcription": transcript,
#             "utterances": utterances,
#             "stage": stage,
#             "question": question,
#             "growth": growth
#         })

#     except Exception as e:
#         traceback.print_exc()
#         return jsonify({"error": str(e)}), 500

# # Run server
# if __name__ == "__main__":
#     app.run(debug=True, host="0.0.0.0", port=5000)

# from flask import Flask, request, jsonify
# from flask_cors import CORS
# from dotenv import load_dotenv
# import os
# import openai  # LEGACY SDK
# import traceback
# import requests

# # Load environment variables
# load_dotenv()
# a4f_api_key = os.getenv("A4F_API_KEY")
# assemblyai_api_key = os.getenv("ASSEMBLYAI_API_KEY")

# if not a4f_api_key or not assemblyai_api_key:
#     raise ValueError("âŒ Missing A4F or AssemblyAI API key in .env")

# # Setup A4F GPT-compatible client using legacy OpenAI SDK
# openai.api_key = a4f_api_key
# openai.api_base = "https://api.a4f.co/v1"

# app = Flask(__name__)
# CORS(app)

# STAGES = ["Beige", "Purple", "Red", "Blue", "Orange", "Green", "Yellow", "Turquoise"]

# # Core Functions
# def detect_intent(entry):
#     prompt = (
#         "You are a gatekeeper. Is this journal entry about personal reflection, values, or growth (Spiral Dynamics)? "
#         "Or is it just casual talk?\n\n"
#         "Reply with one word only: 'spiral' or 'chat'.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0,
#     )
#     return "spiral" if "spiral" in response.choices[0].message["content"].lower() else "chat"

# def classify_stage(entry):
#     prompt = (
#         f"Analyze the user's entry and return only the Spiral Dynamics stage (one of: {', '.join(STAGES)}). "
#         f"Respond only with the stage name.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.6,
#     )
#     return response.choices[0].message["content"].strip()

# def generate_reflective_question(entry, reply_to=None):
#     context = f"\nReplying to: \"{reply_to}\"" if reply_to else ""
#     prompt = (
#         f"You are a Spiral Dynamics mentor. Based on the user's thoughts{context}, "
#         f"ask one deep, emotionally resonant question. "
#         f"Don't mention Spiral Dynamics. Don't explain anything. Just ask the question.\n\n"
#         f"User message: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.85,
#     )
#     return response.choices[0].message["content"].strip()

# def generate_growth_prompt(entry, stage):
#     prompt = (
#         f"User is currently reflecting at Spiral Dynamics stage: {stage}. "
#         f"Based on this short journal entry, give one brief nudge or thought that could help them evolve. "
#         f"Don't say it's a growth tip. Don't label it. Just give a sentence that feels natural and empowering.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.8,
#     )
#     return response.choices[0].message["content"].strip()

# def check_evolution(last_stage, current_stage):
#     try:
#         if STAGES.index(current_stage) > STAGES.index(last_stage):
#             return f"ðŸŒ± Beautiful shift! You've evolved to {current_stage} â€” keep growing ðŸŒŸ"
#     except:
#         pass
#     return None

# # TEXT endpoint
# @app.route("/merged", methods=["POST"])
# def merged_reflection():
#     try:
#         data = request.get_json()
#         entry = data.get("text", "").strip()
#         last_stage = data.get("last_stage", "").strip()
#         reply_to = data.get("reply_to", "").strip()

#         if not entry:
#             return jsonify({"error": "Missing journaling input."}), 400

#         intent = detect_intent(entry)

#         if intent == "chat":
#             message = f"User: {reply_to}\n\nUser response: {entry}" if reply_to else entry
#             reply = openai.ChatCompletion.create(
#                 model="provider-3/gpt-4o",
#                 messages=[{"role": "user", "content": f"You are a kind friend. Respond casually to: {message}"}],
#                 temperature=0.7,
#             )
#             return jsonify({
#                 "mode": "chat",
#                 "response": reply.choices[0].message["content"].strip()
#             })

#         stage = classify_stage(entry)
#         question = generate_reflective_question(entry, reply_to)
#         evolution_msg = check_evolution(last_stage, stage)
#         growth = generate_growth_prompt(entry, stage)

#         return jsonify({
#             "mode": "spiral",
#             "stage": stage,
#             "question": question,
#             "evolution": evolution_msg,
#             "growth": growth
#         })

#     except Exception as e:
#         traceback.print_exc()
#         return jsonify({"error": str(e)}), 500

# # AUDIO endpoint
# from collections import defaultdict

# @app.route("/reflect_transcription", methods=["POST"])
# def reflect_from_audio():
#     try:
#         if "file" not in request.files:
#             return jsonify({"error": "Missing audio file"}), 400

#         audio_file = request.files["file"]

#         # Step 1: Upload audio
#         upload_response = requests.post(
#             "https://api.assemblyai.com/v2/upload",
#             headers={
#                 "authorization": assemblyai_api_key,
#                 "content-type": "application/octet-stream"
#             },
#             data=audio_file.read()
#         )
#         upload_response.raise_for_status()
#         audio_url = upload_response.json()["upload_url"]

#         # Step 2: Request transcription with enhanced options
#         transcript_response = requests.post(
#             "https://api.assemblyai.com/v2/transcript",
#             headers={
#                 "authorization": assemblyai_api_key,
#                 "content-type": "application/json"
#             },
#             json={
#                 "audio_url": audio_url,
#                 "speaker_labels": True,
#                 "punctuate": True,
#                 "format_text": True,
#                 "language_code": "en_us"
#             }
#         )
#         transcript_response.raise_for_status()
#         transcript_id = transcript_response.json()["id"]

#         # Step 3: Poll until complete
#         while True:
#             poll = requests.get(
#                 f"https://api.assemblyai.com/v2/transcript/{transcript_id}",
#                 headers={"authorization": assemblyai_api_key}
#             )
#             result = poll.json()
#             if result["status"] in ("completed", "error"):
#                 break

#         if result["status"] == "error":
#             return jsonify({"error": f"Transcription failed: {result.get('error')}"}), 500

#         utterances = result.get("utterances", [])
#         if not utterances:
#             return jsonify({"error": "No utterances found."}), 400

#         # Step 4: Combine transcript & segment by speaker
#         transcript = "\n".join([f"Speaker {u['speaker']}: {u['text']}" for u in utterances])
#         speaker_texts = defaultdict(str)
#         for utt in utterances:
#             speaker_texts[f"Speaker {utt['speaker']}"] += utt["text"].strip() + " "

#         # Step 5: Run Spiral Dynamics analysis per speaker
#         speaker_analysis = []
#         spiral_detected = False

#         for speaker, speech in speaker_texts.items():
#             speech = speech.strip()
#             if not speech:
#                 continue

#             intent = detect_intent(speech)
#             entry = {
#                 "speaker": speaker,
#                 "intent": intent,
#                 "text": speech
#             }

#             if intent == "spiral":
#                 spiral_detected = True
#                 stage = classify_stage(speech)
#                 question = generate_reflective_question(speech)
#                 growth = generate_growth_prompt(speech, stage)

#                 entry.update({
#                     "stage": stage,
#                     "question": question,
#                     "growth": growth
#                 })
#             else:
#                 reply = openai.ChatCompletion.create(
#                     model="provider-3/gpt-4o",
#                     messages=[{"role": "user", "content": f"You are a kind friend. Respond casually to: {speech}"}],
#                     temperature=0.7,
#                 )
#                 entry["response"] = reply.choices[0].message["content"].strip()

#             speaker_analysis.append(entry)

#         # Final response
#         return jsonify({
#             "mode": "spiral" if spiral_detected else "chat",
#             "transcription": transcript,
#             "utterances": utterances,
#             "analysis": speaker_analysis
#         })

#     except Exception as e:
#         traceback.print_exc()
#         return jsonify({"error": str(e)}), 500
# # Run server
# if __name__ == "__main__":
#     app.run(debug=True, host="0.0.0.0", port=5000)

# @app.route("/reflect_transcription", methods=["POST"])
# def reflect_from_audio():
#     try:
#         if "file" not in request.files:
#             return jsonify({"error": "Missing audio file"}), 400

#         audio_file = request.files["file"]

#         # Step 1: Upload to AssemblyAI (as raw binary)
#         upload_response = requests.post(
#             "https://api.assemblyai.com/v2/upload",
#             headers={
#                 "authorization": assemblyai_api_key,
#                 "content-type": "application/octet-stream"
#             },
#             data=audio_file.read()
#         )
#         upload_response.raise_for_status()
#         audio_url = upload_response.json()["upload_url"]

#         # Step 2: Start transcription with speaker diarization
#         transcript_response = requests.post(
#             "https://api.assemblyai.com/v2/transcript",
#             headers={
#                 "authorization": assemblyai_api_key,
#                 "content-type": "application/json"
#             },
#             json={
#                 "audio_url": audio_url,
#                 "speaker_labels": True,
#                 "language_code": "en_us"
#             }
#         )
#         transcript_response.raise_for_status()
#         transcript_id = transcript_response.json()["id"]

#         # Step 3: Poll until transcription completes
#         while True:
#             poll = requests.get(
#                 f"https://api.assemblyai.com/v2/transcript/{transcript_id}",
#                 headers={"authorization": assemblyai_api_key}
#             )
#             result = poll.json()
#             if result["status"] in ("completed", "error"):
#                 break

#         if result["status"] == "error":
#             return jsonify({"error": f"Transcription failed: {result.get('error')}"}), 500

#         utterances = result.get("utterances", [])
#         if utterances and len(set(u["speaker"] for u in utterances)) > 1:
#             transcript = "\n".join([f"Speaker {u['speaker']}: {u['text']}" for u in utterances])
#         else:
#             transcript = result.get("text", "")

#         # ðŸ§  Apply GPT logic to full transcript
#         entry = transcript.strip()
#         if not entry:
#             return jsonify({"error": "Transcription was empty."}), 400

#         intent = detect_intent(entry)

#         if intent == "chat":
#             reply = openai.ChatCompletion.create(
#                 model="provider-3/gpt-4o",
#                 messages=[{"role": "user", "content": f"You are a kind friend. Respond casually to: {entry}"}],
#                 temperature=0.7,
#             )
#             return jsonify({
#                 "mode": "chat",
#                 "response": reply.choices[0].message["content"].strip(),
#                 "transcription": transcript,
#                 "utterances": utterances
#             })

#         stage = classify_stage(entry)
#         question = generate_reflective_question(entry)
#         growth = generate_growth_prompt(entry, stage)

#         return jsonify({
#             "mode": "spiral",
#             "transcription": transcript,
#             "utterances": utterances,
#             "stage": stage,
#             "question": question,
#             "growth": growth
#         })

#     except Exception as e:
#         traceback.print_exc()
# #         return jsonify({"error": str(e)}), 500
# from flask import Flask, request, jsonify
# from flask_cors import CORS
# from dotenv import load_dotenv
# import os
# import openai  # LEGACY SDK
# import traceback
# import requests
# from collections import defaultdict

# # Load environment variables
# load_dotenv()
# a4f_api_key = os.getenv("A4F_API_KEY")
# assemblyai_api_key = os.getenv("ASSEMBLYAI_API_KEY")

# if not a4f_api_key or not assemblyai_api_key:
#     raise ValueError("âŒ Missing A4F or AssemblyAI API key in .env")

# # Setup A4F GPT-compatible client using legacy OpenAI SDK
# openai.api_key = a4f_api_key
# openai.api_base = "https://api.a4f.co/v1"

# app = Flask(__name__)
# CORS(app)

# STAGES = ["Beige", "Purple", "Red", "Blue", "Orange", "Green", "Yellow", "Turquoise"]

# # Core Functions
# def detect_intent(entry):
#     prompt = (
#         "You are a Spiral Dynamics gatekeeper.\n"
#         "Determine if this journal entry reflects emotional expression, life struggle, desire for change, personal values, reflection, or self-awareness.\n"
#         "If yes, return 'spiral'. If it's only surface-level chat, jokes, or small talk, return 'chat'.\n"
#         "Reply with one word only: 'spiral' or 'chat'.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0,
#     )
#     return "spiral" if "spiral" in response.choices[0].message["content"].lower() else "chat"

# def classify_stage(entry):
#     prompt = (
#         f"Analyze the user's entry and return only the Spiral Dynamics stage (one of: {', '.join(STAGES)}). "
#         f"Respond only with the stage name.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.6,
#     )
#     return response.choices[0].message["content"].strip()

# def generate_reflective_question(entry, reply_to=None):
#     context = f"\nReplying to: \"{reply_to}\"" if reply_to else ""
#     prompt = (
#         f"You are a Spiral Dynamics mentor. Based on the user's thoughts{context}, "
#         f"ask one deep, emotionally resonant question. "
#         f"Don't mention Spiral Dynamics. Don't explain anything. Just ask the question.\n\n"
#         f"User message: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.85,
#     )
#     return response.choices[0].message["content"].strip()

# def generate_growth_prompt(entry, stage):
#     prompt = (
#         f"User is currently reflecting at Spiral Dynamics stage: {stage}. "
#         f"Based on this short journal entry, give one brief nudge or thought that could help them evolve. "
#         f"Don't say it's a growth tip. Don't label it. Just give a sentence that feels natural and empowering.\n\n"
#         f"Entry: \"{entry}\""
#     )
#     response = openai.ChatCompletion.create(
#         model="provider-3/gpt-4o",
#         messages=[{"role": "user", "content": prompt}],
#         temperature=0.8,
#     )
#     return response.choices[0].message["content"].strip()

# def check_evolution(last_stage, current_stage):
#     try:
#         if STAGES.index(current_stage) > STAGES.index(last_stage):
#             return f"ðŸŒ± Beautiful shift! You've evolved to {current_stage} â€” keep growing ðŸŒŸ"
#     except:
#         pass
#     return None

# # TEXT endpoint
# @app.route("/merged", methods=["POST"])
# def merged_reflection():
#     try:
#         data = request.get_json()
#         entry = data.get("text", "").strip()
#         last_stage = data.get("last_stage", "").strip()
#         reply_to = data.get("reply_to", "").strip()

#         if not entry:
#             return jsonify({"error": "Missing journaling input."}), 400

#         intent = detect_intent(entry)

#         if intent == "chat":
#             message = f"User: {reply_to}\n\nUser response: {entry}" if reply_to else entry
#             reply = openai.ChatCompletion.create(
#                 model="provider-3/gpt-4o",
#                 messages=[{"role": "user", "content": f"You are a kind friend. Respond casually to: {message}"}],
#                 temperature=0.7,
#             )
#             return jsonify({
#                 "mode": "chat",
#                 "response": reply.choices[0].message["content"].strip()
#             })

#         stage = classify_stage(entry)
#         question = generate_reflective_question(entry, reply_to)
#         evolution_msg = check_evolution(last_stage, stage)
#         growth = generate_growth_prompt(entry, stage)

#         return jsonify({
#             "mode": "spiral",
#             "stage": stage,
#             "question": question,
#             "evolution": evolution_msg,
#             "growth": growth
#         })

#     except Exception as e:
#         traceback.print_exc()
#         return jsonify({"error": str(e)}), 500

# # AUDIO endpoint
# @app.route("/reflect_transcription", methods=["POST"])
# def reflect_from_audio():
#     try:
#         if "file" not in request.files:
#             return jsonify({"error": "Missing audio file"}), 400

#         audio_file = request.files["file"]

#         # Step 1: Upload audio
#         upload_response = requests.post(
#             "https://api.assemblyai.com/v2/upload",
#             headers={
#                 "authorization": assemblyai_api_key,
#                 "content-type": "application/octet-stream"
#             },
#             data=audio_file.read()
#         )
#         upload_response.raise_for_status()
#         audio_url = upload_response.json()["upload_url"]

#         # Step 2: Request transcription with enhanced options
#         transcript_response = requests.post(
#             "https://api.assemblyai.com/v2/transcript",
#             headers={
#                 "authorization": assemblyai_api_key,
#                 "content-type": "application/json"
#             },
#             json={
#                 "audio_url": audio_url,
#                 "speaker_labels": True,
#                 "punctuate": True,
#                 "format_text": True,
#                 "language_code": "en_us"
#             }
#         )
#         transcript_response.raise_for_status()
#         transcript_id = transcript_response.json()["id"]

#         # Step 3: Poll until complete
#         while True:
#             poll = requests.get(
#                 f"https://api.assemblyai.com/v2/transcript/{transcript_id}",
#                 headers={"authorization": assemblyai_api_key}
#             )
#             result = poll.json()
#             if result["status"] in ("completed", "error"):
#                 break

#         if result["status"] == "error":
#             return jsonify({"error": f"Transcription failed: {result.get('error')}"}), 500

#         utterances = result.get("utterances", [])
#         if not utterances:
#             return jsonify({"error": "No utterances found."}), 400

#         # Step 4: Combine transcript & segment by speaker
#         transcript = "\n".join([f"Speaker {u['speaker']}: {u['text']}" for u in utterances])
#         speaker_texts = defaultdict(str)
#         for utt in utterances:
#             speaker_texts[f"Speaker {utt['speaker']}"] += utt["text"].strip() + " "

#         # Step 5: Run Spiral Dynamics analysis per speaker
#         speaker_analysis = []
#         spiral_detected = False

#         for speaker, speech in speaker_texts.items():
#             speech = speech.strip()
#             if not speech:
#                 continue

#             intent = detect_intent(speech)
#             entry = {
#                 "speaker": speaker,
#                 "intent": intent,
#                 "text": speech
#             }

#             if intent == "spiral":
#                 spiral_detected = True
#                 stage = classify_stage(speech)
#                 question = generate_reflective_question(speech)
#                 growth = generate_growth_prompt(speech, stage)

#                 entry.update({
#                     "stage": stage,
#                     "question": question,
#                     "growth": growth
#                 })
#             else:
#                 reply = openai.ChatCompletion.create(
#                     model="provider-3/gpt-4o",
#                     messages=[{"role": "user", "content": f"You are a kind friend. Respond casually to: {speech}"}],
#                     temperature=0.7,
#                 )
#                 entry["response"] = reply.choices[0].message["content"].strip()

#             speaker_analysis.append(entry)

#         # Final response
#         return jsonify({
#             "mode": "spiral" if spiral_detected else "chat",
#             "transcription": transcript,
#             "utterances": utterances,
#             "analysis": speaker_analysis
#         })

#     except Exception as e:
#         traceback.print_exc()
#         return jsonify({"error": str(e)}), 500

# # Run server
# if __name__ == "__main__":
#     app.run(debug=True, host="0.0.0.0", port=5000)